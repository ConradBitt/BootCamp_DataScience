{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "union-alliance",
   "metadata": {},
   "source": [
    "# Objetivo: Previsão de pacientes na UTI (COVID-19)\n",
    "\n",
    "Utilizarei a base de dados do Hospital Sírio Libanês. A base de dados esta disponível no site do [Kaggle](https://www.kaggle.com/) na pagina do grupo do Sírio Libanês [COVID-19 - Clinical Data to assess diagnosis](https://www.kaggle.com/S%C3%ADrio-Libanes/covid19).\n",
    "\n",
    "Essa base de dados contém informações, não sensíveis, que diz respeito a quantidade de pacientes que foram ou não internados por covid-19 na clínica do hospital durante a pandemia de corona virus. As informações são ricas com respeito ao quadro clínico e a pergunta que vamos tentar responder é: \n",
    "\n",
    "> **Dado um novo paciente conseguiremos prever a chance dele ser encaminhado para a UTI?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "economic-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlling-lightning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1925 entries, 0 to 1924\n",
      "Columns: 231 entries, PATIENT_VISIT_IDENTIFIER to ICU\n",
      "dtypes: float64(225), int64(4), object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "sirio_libanes = pd.read_excel('dados/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\n",
    "sirio_libanes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pending-india",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>728</th>\n",
       "      <th>877</th>\n",
       "      <th>599</th>\n",
       "      <th>1816</th>\n",
       "      <th>939</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
       "      <td>145</td>\n",
       "      <td>175</td>\n",
       "      <td>119</td>\n",
       "      <td>363</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE_ABOVE65</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE_PERCENTIL</th>\n",
       "      <td>Above 90th</td>\n",
       "      <td>30th</td>\n",
       "      <td>20th</td>\n",
       "      <td>90th</td>\n",
       "      <td>70th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENDER</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISEASE GROUPING 1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
       "      <td>-0.634409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.939068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEMPERATURE_DIFF_REL</th>\n",
       "      <td>-0.906821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.340619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.928473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
       "      <td>-0.980232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.940077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WINDOW</th>\n",
       "      <td>6-12</td>\n",
       "      <td>4-6</td>\n",
       "      <td>ABOVE_12</td>\n",
       "      <td>2-4</td>\n",
       "      <td>ABOVE_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICU</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  728   877       599   1816      939 \n",
       "PATIENT_VISIT_IDENTIFIER           145   175       119   363       187\n",
       "AGE_ABOVE65                          1     0         0     1         1\n",
       "AGE_PERCENTIL               Above 90th  30th      20th  90th      70th\n",
       "GENDER                               1     1         0     0         0\n",
       "DISEASE GROUPING 1                 0.0   0.0       0.0   0.0       0.0\n",
       "...                                ...   ...       ...   ...       ...\n",
       "RESPIRATORY_RATE_DIFF_REL    -0.634409   NaN  0.206452   NaN -0.939068\n",
       "TEMPERATURE_DIFF_REL         -0.906821   NaN -0.340619   NaN -0.928473\n",
       "OXYGEN_SATURATION_DIFF_REL   -0.980232   NaN  0.513836   NaN -0.940077\n",
       "WINDOW                            6-12   4-6  ABOVE_12   2-4  ABOVE_12\n",
       "ICU                                  1     0         1     0         0\n",
       "\n",
       "[231 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sirio_libanes.sample(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-miami",
   "metadata": {},
   "source": [
    "## Tarefas impostas pelo Kaggle \n",
    "\n",
    "> **Task 1**: Preve a admissão na UTI os casos confirmados de covid-19. Com base na amostra acima, verificar a viabilidade de previsão/classificação dos pacientes que precisarão ou não do suporte de terapia intensiva do hospital. O objetivo é fornecer ao hospital uma previsão de quatro ou três semenas de antecedência da forma mais acurada possível para que os recursos utilizados na UTI possam ser arranjados ou remanejados. \n",
    "\n",
    "> **Task 2**: Prever a **NÃO** admissão dos casos de covid-19 na UTI. Com base na amostra dos dados, prever quais pacientes não preciarão de suporte a unidade de terapia intensiva. O objetivo é fornecer aos hospitais temporários e locais uma resposta boa o suficiente para que os médicos de linha de frente possam dar alta com segurança e acompanhar pacientes remotamente.\n",
    "\n",
    "Note que o objetivo não se reduz a fazer uma análise de estatistica descritiva, o objetivo é classificação de pacientes que precisarão de uma UTI ou não. Ou seja, **uma classificação binária.**\n",
    "\n",
    "---\n",
    "\n",
    "## Vamos verificar qual a quantidade dos dados que foram ou não pra UTI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranking-quebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73.0\n",
       "1    27.0\n",
       "Name: ICU, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sirio_libanes['ICU'].value_counts(normalize=True).round(2)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-slope",
   "metadata": {},
   "source": [
    "### Comentário sobre a proporção de pacientes que precisaram da UTI\n",
    "> Acima podemos verificar que nesta base de dados, dentre os 1924 registros, a quantidade de pessoas que evoluem até a situação em que necessitam de uma UTI é de quase 27%, os outros 73% precisaram do serviço."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-princeton",
   "metadata": {},
   "source": [
    "## A respeito da anonimização dos dados\n",
    "\n",
    "A Lei Geral de Proteção de Dados Pessoais (LGPD), Lei nº 13.709, de 14 de agosto de 2018, dispõe sobre o tratamento de dados pessoais, inclusive nos meios digitais, por pessoa natural ou por pessoa jurídica de direito público ou privado, com o objetivo de proteger os direitos fundamentais de liberdade e de privacidade e o livre desenvolvimento da personalidade da pessoa natural. \n",
    "\n",
    "Tendo em vista a vigência dessa Lei, de suma importancia pra sociedade, é importante que os dados sejam anonimizados para respeitar os direitos dos cidadãos brasileiros. É importante citar isso pois anonimização de um dado deve ser muito bem feita afim de não violar o direito dos individuos.\n",
    "\n",
    "Note que só o fato de sabermos que a mostra foi retirada dentre os pacientes do Hospital Sírio Libanês em um intervalo X de tempo já reduz muito o fator de anonimidade do dado e se uma variável fosse explicitamente a comorbidade \"diabetes\", \"pressão alta\" ou \"HIV\", caso as variáveis não fossem *clusterizadas*, sabendo a prevalência de uma doença numa população é possível encontrar as características de cada amostra e é importante dificultar este tipo de análise para estar de acordo com a lei de proteção de dados.\n",
    "\n",
    "Uma forma de anonimizar esses dados é criar grupos de características entre as amostras evitando assim de informar exatamente quais são as características de um elemento da base de dados. \n",
    "\n",
    "fonte: [Lei Geral de Proteção de Dados - LGPD](https://www.gov.br/defesa/pt-br/acesso-a-informacao/lei-geral-de-protecao-de-dados-pessoais-lgpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-progress",
   "metadata": {},
   "source": [
    "## Propondo modelo Linear\n",
    "\n",
    "Um modelo matemático pode ser expresso em uma função, tal que: \n",
    "\n",
    "### $$\\vec{y} = \\vec{f}(\\vec{x})$$\n",
    "\n",
    "no caso $\\vec{f}$  é um operador vetorial que irá realizar alguma transformação nos dados $\\vec{x}$ resultando em $\\vec{y}$. Note que em geral temos $\\vec{x}$ e $\\vec{y}$ e queremos ajustar um modelo $\\vec{f}$.\n",
    "\n",
    "### Dados de treino e dados de teste\n",
    "\n",
    "Técnicas de regressão em geral tentam ajustar uma curva a um conjunto de dados e posteriormente após ter a curva parte da análise é entender como variam os **resíduos** que no caso é a diferença entre um dado e o resultado predito pelo modelo. Em aprendizado de máquina esta técnica também é utilizada porém com uma modificação.\n",
    "\n",
    "Os dados que serão fornecidos pelo modelo são classificados em **dados de treino** e **dados de teste**. Aos dados de treino a técnica é exatamente a mesma usada em técnica de regressões: \n",
    "\n",
    "> Usa $x$ **entradas de treino** pra ajustar um modelo $f$ que vai calcular uma **saida** $y'$ prevista pelo modelo. Então compara-se $y$ real com $y'$ previsto.\n",
    "\n",
    "A introdução do conceito dos **dados de teste** é garantir que mesmo que com $x$ dados de entrada nunca vistos o modelo $f$ consegue ainda assim abstrair novas informações nunca vistas afim de estimar $y'$ cujo o resultado é o melhor valor de $y$.\n",
    "\n",
    "> Usa $x$ entradas de treino pra ajustar um modelo $f$ que vai calcular uma saida $y'$ prevista pelo modelo. Então compara-se $y$ real com $y'$ previsto. Agora afim de testar a abstração do modelo, fornecemos $X$ **entradas de teste** para verificar a precisão de $f$ ao gerar $Y'$ **saidas previstas** em relação aos $Y$ **saidas de teste**\n",
    "\n",
    "Um ponto importante é que a abstração do modelo esta sempre quantificada em relação aos dados de teste, não aos dados de treino. Isso porque os dados de treino são usados para treinar e estimar um modelo, já os dados de teste são dados que o modelo não teve contato e portanto as informações do $X_{teste}$ são novas ao modelo então precisamos verificar o quão bom o modelo é pra para estimar resultados em cima de dados que ele nunca viu antes. Uma forma bem simples de entender esse algorítmo de treinamento e teste é: \n",
    "\n",
    "1. Separa a base de dados em dados de treino e dados de teste.\n",
    "2. Usa os dados de treino ($x,y$) para ajustar $f$.\n",
    "3. Usa o modelo $f$ ajustado em dados de teste.\n",
    "4. Comparar sempre o resultado em relação aos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "coupled-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 545 entries, 4 to 1924\n",
      "Columns: 229 entries, PATIENT_VISIT_IDENTIFIER to ICU\n",
      "dtypes: float64(225), int64(4)\n",
      "memory usage: 979.3 KB\n"
     ]
    }
   ],
   "source": [
    "colunas_quantitativas = sirio_libanes.describe().columns\n",
    "\n",
    "sirio_libanes_quantitativos = sirio_libanes[colunas_quantitativas].dropna()\n",
    "sirio_libanes_quantitativos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "combined-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sirio_libanes_quantitativos['ICU']\n",
    "x = sirio_libanes_quantitativos.drop('ICU', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "absolute-connecticut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(545, 228)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y.shape)\n",
    "display(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-snapshot",
   "metadata": {},
   "source": [
    "### Modelo de Regressão Logística\n",
    "\n",
    "A regressão logística é uma técnica estatística que tem como objetivo produzir, a partir de um conjunto de observações, um modelo que permita a predição de valores tomados por uma variável categórica, frequentemente binária, a partir de uma série de variáveis explicativas contínuas e/ou binárias.\n",
    "\n",
    "* Em medicina, permite por exemplo determinar os factores que caracterizam um grupo de indivíduos doentes em relação a indivíduos sãos.\n",
    "* No domínio dos seguros, permite encontrar fracções da clientela que sejam sensíveis a determinada política securitária em relação a um dado risco particular.\n",
    "* Em instituições financeiras, pode detectar os grupos de risco para a subscrição de um crédito.\n",
    "* Em econometria, permite explicar uma variável discreta, como por exemplo as intenções de voto em actos eleitorais.\n",
    "\n",
    "#### Considerações do modelo: \n",
    "* Relação linear entre o vetor das variáveis explicativas X e o logit da variável resposta Y\n",
    "* Ausência de multicolinearidade\n",
    "* Valor esperado dos resíduos igual a zero\n",
    "* Ausência de heterocedasticidade\n",
    "* Não pressupõe normalidade dos resíduos nem homogeneidade de variâncias. \n",
    "\n",
    "#### SK Learn\n",
    "```python\n",
    "sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "```\n",
    "[[source]](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "instrumental-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "impaired-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_regressao_logistica = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "narrative-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6a6b694831bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelo_regressao_logistica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1417\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    762\u001b[0m             n_iter_i = _check_optimize_result(\n\u001b[1;32m    763\u001b[0m                 \u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                 extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n\u001b[0m\u001b[1;32m    765\u001b[0m             \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_check_optimize_result\u001b[0;34m(solver, result, max_iter, extra_warning_msg)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0;34m\"    https://scikit-learn.org/stable/modules/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;34m\"preprocessing.html\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             ).format(solver, result.status, result.message.decode(\"latin1\"))\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_warning_msg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mwarning_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_warning_msg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "modelo_regressao_logistica.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-festival",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
