{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Modulo_5_ML_Sirio_Libanes.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "union-alliance"
      },
      "source": [
        "# Objetivo: Previsão de pacientes na UTI (COVID-19)\n",
        "\n",
        "Utilizarei a base de dados do Hospital Sírio Libanês. A base de dados esta disponível no site do [Kaggle](https://www.kaggle.com/) na pagina do grupo do Sírio Libanês [COVID-19 - Clinical Data to assess diagnosis](https://www.kaggle.com/S%C3%ADrio-Libanes/covid19).\n",
        "\n",
        "Essa base de dados contém informações, não sensíveis, que diz respeito a quantidade de pacientes que foram ou não internados por covid-19 na clínica do hospital durante a pandemia de corona virus. As informações são ricas com respeito ao quadro clínico e a pergunta que vamos tentar responder é: \n",
        "\n",
        "> **Dado um novo paciente conseguiremos prever a chance dele ser encaminhado para a UTI?**\n"
      ],
      "id": "union-alliance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "economic-biology"
      },
      "source": [
        "import pandas as pd"
      ],
      "id": "economic-biology",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "controlling-lightning",
        "outputId": "7546df3b-9493-445c-b512-4060e31774ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sirio_libanes = pd.read_excel('https://github.com/ConradBitt/BootCamp_DataScience/blob/master/ML%20em%20Saude/dados/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx?raw=true')\n",
        "sirio_libanes.info()"
      ],
      "id": "controlling-lightning",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1925 entries, 0 to 1924\n",
            "Columns: 231 entries, PATIENT_VISIT_IDENTIFIER to ICU\n",
            "dtypes: float64(225), int64(4), object(2)\n",
            "memory usage: 3.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pending-india",
        "outputId": "a3b22f90-75ad-4174-ecfb-d933a04fd47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "sirio_libanes.sample(5).T"
      ],
      "id": "pending-india",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1187</th>\n",
              "      <th>648</th>\n",
              "      <th>1381</th>\n",
              "      <th>570</th>\n",
              "      <th>1323</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <td>237</td>\n",
              "      <td>129</td>\n",
              "      <td>276</td>\n",
              "      <td>114</td>\n",
              "      <td>264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE_ABOVE65</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE_PERCENTIL</th>\n",
              "      <td>40th</td>\n",
              "      <td>20th</td>\n",
              "      <td>50th</td>\n",
              "      <td>20th</td>\n",
              "      <td>60th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GENDER</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DISEASE GROUPING 1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.451613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TEMPERATURE_DIFF_REL</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.819023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.899078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WINDOW</th>\n",
              "      <td>4-6</td>\n",
              "      <td>6-12</td>\n",
              "      <td>2-4</td>\n",
              "      <td>0-2</td>\n",
              "      <td>6-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ICU</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>231 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            1187  648   1381  570       1323\n",
              "PATIENT_VISIT_IDENTIFIER     237   129   276   114       264\n",
              "AGE_ABOVE65                    0     0     0     0         1\n",
              "AGE_PERCENTIL               40th  20th  50th  20th      60th\n",
              "GENDER                         0     0     0     1         1\n",
              "DISEASE GROUPING 1             0     0     0     0         0\n",
              "...                          ...   ...   ...   ...       ...\n",
              "RESPIRATORY_RATE_DIFF_REL     -1    -1   NaN    -1 -0.451613\n",
              "TEMPERATURE_DIFF_REL          -1    -1   NaN    -1 -0.819023\n",
              "OXYGEN_SATURATION_DIFF_REL    -1    -1   NaN    -1 -0.899078\n",
              "WINDOW                       4-6  6-12   2-4   0-2      6-12\n",
              "ICU                            0     0     0     0         0\n",
              "\n",
              "[231 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ignored-miami"
      },
      "source": [
        "## Tarefas impostas pelo Kaggle \n",
        "\n",
        "> **Task 1**: Preve a admissão na UTI os casos confirmados de covid-19. Com base na amostra acima, verificar a viabilidade de previsão/classificação dos pacientes que precisarão ou não do suporte de terapia intensiva do hospital. O objetivo é fornecer ao hospital uma previsão de quatro ou três semenas de antecedência da forma mais acurada possível para que os recursos utilizados na UTI possam ser arranjados ou remanejados. \n",
        "\n",
        "> **Task 2**: Prever a **NÃO** admissão dos casos de covid-19 na UTI. Com base na amostra dos dados, prever quais pacientes não preciarão de suporte a unidade de terapia intensiva. O objetivo é fornecer aos hospitais temporários e locais uma resposta boa o suficiente para que os médicos de linha de frente possam dar alta com segurança e acompanhar pacientes remotamente.\n",
        "\n",
        "Note que o objetivo não se reduz a fazer uma análise de estatistica descritiva, o objetivo é classificação de pacientes que precisarão de uma UTI ou não. Ou seja, **uma classificação binária.**\n",
        "\n",
        "---\n",
        "\n",
        "## Vamos verificar qual a quantidade dos dados que foram ou não pra UTI:"
      ],
      "id": "ignored-miami"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ranking-quebec",
        "outputId": "7ec42167-aade-48c2-9d89-ca18093eebdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sirio_libanes['ICU'].value_counts(normalize=True).round(2)*100"
      ],
      "id": "ranking-quebec",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    73.0\n",
              "1    27.0\n",
              "Name: ICU, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "assumed-slope"
      },
      "source": [
        "### Comentário sobre a proporção de pacientes que precisaram da UTI\n",
        "> Acima podemos verificar que nesta base de dados, dentre os 1924 registros, a quantidade de pessoas que evoluem até a situação em que necessitam de uma UTI é de quase 27%, os outros 73% precisaram do serviço."
      ],
      "id": "assumed-slope"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spoken-princeton"
      },
      "source": [
        "## A respeito da anonimização dos dados\n",
        "\n",
        "A Lei Geral de Proteção de Dados Pessoais (LGPD), Lei nº 13.709, de 14 de agosto de 2018, dispõe sobre o tratamento de dados pessoais, inclusive nos meios digitais, por pessoa natural ou por pessoa jurídica de direito público ou privado, com o objetivo de proteger os direitos fundamentais de liberdade e de privacidade e o livre desenvolvimento da personalidade da pessoa natural. \n",
        "\n",
        "Tendo em vista a vigência dessa Lei, de suma importancia pra sociedade, é importante que os dados sejam anonimizados para respeitar os direitos dos cidadãos brasileiros. É importante citar isso pois anonimização de um dado deve ser muito bem feita afim de não violar o direito dos individuos.\n",
        "\n",
        "Note que só o fato de sabermos que a mostra foi retirada dentre os pacientes do Hospital Sírio Libanês em um intervalo X de tempo já reduz muito o fator de anonimidade do dado e se uma variável fosse explicitamente a comorbidade \"diabetes\", \"pressão alta\" ou \"HIV\", caso as variáveis não fossem *clusterizadas*, sabendo a prevalência de uma doença numa população é possível encontrar as características de cada amostra e é importante dificultar este tipo de análise para estar de acordo com a lei de proteção de dados.\n",
        "\n",
        "Uma forma de anonimizar esses dados é criar grupos de características entre as amostras evitando assim de informar exatamente quais são as características de um elemento da base de dados. \n",
        "\n",
        "fonte: [Lei Geral de Proteção de Dados - LGPD](https://www.planalto.gov.br/ccivil_03/_Ato2015-2018/2018/Lei/L13709.htm#ementa)"
      ],
      "id": "spoken-princeton"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ancient-progress"
      },
      "source": [
        "## Propondo modelo Linear\n",
        "\n",
        "Um modelo matemático pode ser expresso em uma função, tal que: \n",
        "\n",
        "### $$\\vec{y} = \\vec{f}(\\vec{x})$$\n",
        "\n",
        "no caso $\\vec{f}$  é um operador vetorial que irá realizar alguma transformação nos dados $\\vec{x}$ resultando em $\\vec{y}$. Note que em geral temos $\\vec{x}$ e $\\vec{y}$ e queremos ajustar um modelo $\\vec{f}$.\n",
        "\n",
        "> O vetor $\\vec{y}$ é chamado de *variável dependente* pois ele é obtido através de uma função do vetor $\\vec{x}$. O vetor $\\vec{x}$ é dito variável independente, pois são dados que o estatistico/médico/pesquisador acredita que possam contribuir para entender o valor de $\\vec{y}$.\n",
        "\n",
        "### Dados de treino e dados de teste\n",
        "\n",
        "Técnicas de regressão em geral tentam ajustar uma curva a um conjunto de dados e posteriormente após ter a curva parte da análise é entender como variam os **resíduos** que no caso é a diferença entre um dado e o resultado predito pelo modelo. Em aprendizado de máquina esta técnica também é utilizada porém com uma modificação.\n",
        "\n",
        "Os dados que serão fornecidos pelo modelo são classificados em **dados de treino** e **dados de teste**. Aos dados de treino a técnica é exatamente a mesma usada em técnica de regressões: \n",
        "\n",
        "> Usa $x$ **entradas de treino** pra ajustar um modelo $f$ que vai calcular uma **saida** $y'$ prevista pelo modelo. Então compara-se $y$ real com $y'$ previsto.\n",
        "\n",
        "A introdução do conceito dos **dados de teste** é garantir que mesmo que com $x$ dados de entrada nunca vistos o modelo $f$ consegue ainda assim abstrair novas informações nunca vistas afim de estimar $y'$ cujo o resultado é o melhor valor de $y$.\n",
        "\n",
        "> Usa $x$ entradas de treino pra ajustar um modelo $f$ que vai calcular uma saida $y'$ prevista pelo modelo. Então compara-se $y$ real com $y'$ previsto. Agora afim de testar a abstração do modelo, fornecemos $X$ **entradas de teste** para verificar a precisão de $f$ ao gerar $Y'$ **saidas previstas** em relação aos $Y$ **saidas de teste**\n",
        "\n",
        "Um ponto importante é que a abstração do modelo esta sempre quantificada em relação aos dados de teste, não aos dados de treino. Isso porque os dados de treino são usados para treinar e estimar um modelo, já os dados de teste são dados que o modelo não teve contato e portanto as informações do $X_{teste}$ são novas ao modelo então precisamos verificar o quão bom o modelo é pra para estimar resultados em cima de dados que ele nunca viu antes. Uma forma bem simples de entender esse algorítmo de treinamento e teste é: \n",
        "\n",
        "1. Separa a base de dados em dados de treino e dados de teste.\n",
        "2. Usa os dados de treino ($x,y$) para ajustar $f$.\n",
        "3. Usa o modelo $f$ ajustado em dados de teste.\n",
        "4. Comparar sempre o resultado em relação aos dados de teste."
      ],
      "id": "ancient-progress"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coupled-teddy",
        "outputId": "34f176cc-5aeb-4549-e8c0-1a895de24644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "colunas_quantitativas = sirio_libanes.describe().columns\n",
        "\n",
        "sirio_libanes_quantitativos = sirio_libanes[colunas_quantitativas].dropna()\n",
        "sirio_libanes_quantitativos.info()"
      ],
      "id": "coupled-teddy",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 545 entries, 4 to 1924\n",
            "Columns: 229 entries, PATIENT_VISIT_IDENTIFIER to ICU\n",
            "dtypes: float64(225), int64(4)\n",
            "memory usage: 979.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "combined-formula"
      },
      "source": [
        "y = sirio_libanes_quantitativos['ICU']\n",
        "x = sirio_libanes_quantitativos.drop('ICU', axis=1)"
      ],
      "id": "combined-formula",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "absolute-connecticut",
        "outputId": "6540c908-59e5-42f6-e52b-b1281aec336f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "display(y.shape)\n",
        "display(x.shape)"
      ],
      "id": "absolute-connecticut",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(545,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(545, 228)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coastal-snapshot"
      },
      "source": [
        "### Modelo de Regressão Logística\n",
        "\n",
        "A regressão logística é uma técnica estatística que tem como objetivo produzir, a partir de um conjunto de observações, um modelo que permita a predição de valores tomados por uma variável categórica, frequentemente binária, a partir de uma série de variáveis explicativas contínuas e/ou binárias.\n",
        "\n",
        "* Em medicina, permite por exemplo determinar os factores que caracterizam um grupo de indivíduos doentes em relação a indivíduos sãos.\n",
        "* No domínio dos seguros, permite encontrar fracções da clientela que sejam sensíveis a determinada política securitária em relação a um dado risco particular.\n",
        "* Em instituições financeiras, pode detectar os grupos de risco para a subscrição de um crédito.\n",
        "* Em econometria, permite explicar uma variável discreta, como por exemplo as intenções de voto em actos eleitorais.\n",
        "\n",
        "#### Considerações do modelo: \n",
        "* Relação linear entre o vetor das variáveis explicativas X e o logit da variável resposta Y\n",
        "* Ausência de multicolinearidade\n",
        "* Valor esperado dos resíduos igual a zero\n",
        "* Ausência de heterocedasticidade\n",
        "* Não pressupõe normalidade dos resíduos nem homogeneidade de variâncias. \n",
        "\n",
        "#### SK Learn\n",
        "```python\n",
        "sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "```\n",
        "[[source]](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ],
      "id": "coastal-snapshot"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "instrumental-perception"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "id": "instrumental-perception",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impaired-exploration"
      },
      "source": [
        "modelo_regressao_logistica = LogisticRegression()"
      ],
      "id": "impaired-exploration",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "narrative-hypothetical",
        "outputId": "d0a98372-7e1c-4eac-d256-0ae25e50737d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "modelo_regressao_logistica.fit(x,y)"
      ],
      "id": "narrative-hypothetical",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMOSxUUHaYM5"
      },
      "source": [
        "Com o modelo treinado (*fit*) podemos usa-lo para predizer algo:"
      ],
      "id": "YMOSxUUHaYM5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adaptive-festival",
        "outputId": "1eb66338-0b1f-4019-b782-cfc34b30086e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "modelo_regressao_logistica.predict([x.iloc[5]])"
      ],
      "id": "adaptive-festival",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8zHHH8Pc4wS"
      },
      "source": [
        "Note que para o dado `[x.iloc[5]]` o modelo sugere um resultado `array([0])` ou seja, que este paciente não vai para a UTI. Podemos verificar esta situação nos dados de saida:"
      ],
      "id": "v8zHHH8Pc4wS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT4FsXYxbv_4",
        "outputId": "4ff1858b-628e-401c-af36-c0433ce04959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.iloc[5]"
      ],
      "id": "fT4FsXYxbv_4",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrERVwYpdNxm"
      },
      "source": [
        "realmente o resultado condiz com a previsão do modelo. Entretanto ainda existe outros dois problemas fundamentais. Primeiro problema é: não adianta acertar **um resultado**, é preciso mensurar a taxa de acerto. O segundo é a **separação entre os dados de treino e teste**, não adianta prever dados que foram usados para ensinar o modelo. "
      ],
      "id": "JrERVwYpdNxm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ttvL6b-eg5o"
      },
      "source": [
        "#### Para resolver o Primeiro problema\n",
        "\n",
        "Em vez de prever um único elemento podemos fornecer vários dados ao mesmo tempo:"
      ],
      "id": "7ttvL6b-eg5o"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxcnb6GecpRc"
      },
      "source": [
        "y_previsto = modelo_regressao_logistica.predict(x)"
      ],
      "id": "Rxcnb6GecpRc",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUCXwjsre8kU"
      },
      "source": [
        "agora basta comparar `y_previsto` com `y`"
      ],
      "id": "hUCXwjsre8kU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2I2QUg3e5cj",
        "outputId": "2ccf8666-b688-452b-dc4d-f644e9668e6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_previsto == y"
      ],
      "id": "a2I2QUg3e5cj",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4        True\n",
              "6        True\n",
              "8        True\n",
              "9        True\n",
              "14       True\n",
              "        ...  \n",
              "1904    False\n",
              "1914     True\n",
              "1919     True\n",
              "1921     True\n",
              "1924     True\n",
              "Name: ICU, Length: 545, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRK_OCzvfGfM"
      },
      "source": [
        "Note que ele retorna um array booleano. Como no python `True == 1` e `False == 0 `"
      ],
      "id": "wRK_OCzvfGfM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-qKW3cle7Xm",
        "outputId": "a724d663-bdb7-47ef-f1c4-05becba8212e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "True == 1 "
      ],
      "id": "I-qKW3cle7Xm",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzBPt_T1fQy2"
      },
      "source": [
        "podemos somar todos os valores do array booleano e verificar quantos foram os acertos:"
      ],
      "id": "ZzBPt_T1fQy2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoBL_ejWfPIc",
        "outputId": "37cc2f19-8dc6-4338-eb9a-4c77672c5fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sum(y_previsto == y)"
      ],
      "id": "GoBL_ejWfPIc",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "497"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l76B1zq_fbze",
        "outputId": "69e154f7-0171-47fb-fb1f-9cc183da1cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sum(y_previsto == y) / len(y) * 100"
      ],
      "id": "l76B1zq_fbze",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91.19266055045871"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mcO63hrfhuE"
      },
      "source": [
        "#### Conclusão a respeito do primeiro problema\n",
        "> Existe uma regra de ouro **\"Se você treinou um modelo e a acurrácia foi de 90% logo na primeira simulação, então provávelmente tem algum engano.\"** \n",
        "\n",
        "> O resultado foi de 497 acertos, uma porporção de 91% dos dados. Esta é uma forma de metrificar a qualidade do modelo, acontece que ainda temos o problema de tentar prever dados que o modelo já utilizou na faze de treino, não é um bom indicador de qualidade testar um modelo em cima dos dados que foram utilizados para treina-lo.\n",
        "\n",
        "\n",
        "### Baseline com Dummy Classifier \n",
        "\n",
        "Além disso, existe a possibilidade do modelo conseguir acertar por mera chance, por exemplo, temos 545 dados, com valor $0$ ou $1$, se o modelo atribuir $1$ para todos, já irá acertar 264 pacientes... Não por previsão mas por mera chance. Existe uma forma de medir essa \"mera chance\" com um classificador \"ingênuo\" ou [\"dummy classifier\"](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.dummy)\n",
        "\n",
        "\n",
        "```python\n",
        "sklearn.dummy.DummyClassifier(*, strategy='prior', random_state=None, constant=None)[source]\n",
        "```\n"
      ],
      "id": "0mcO63hrfhuE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq4g6GH4ffU4",
        "outputId": "d05c2364-511d-4928-8cc0-3b5b789938b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "modelo_dummy = DummyClassifier()\n",
        "modelo_dummy.fit(x, y)\n",
        "sum(modelo_dummy.predict(x) == y) / len(y) * 100"
      ],
      "id": "Eq4g6GH4ffU4",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48.62385321100918"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2plcTcSf_nR"
      },
      "source": [
        "#### Conclusão sobre dummy classifier:\n",
        "> Ou seja, com o ``DummyClassifier`` por mera chance acerta $49,35\\%$ dos dados. Mas não é só ele, se você selecionar uma pessoa qualquer, aleatória, a chance dela acertar se um paciente vai ou não pra UTI é $49,35\\%$.\n",
        "\n",
        "> Note que a estrategia de decisão classifier esta na documentaçãão dizendo **“prior”: always predicts the class that maximizes the class prior (like “most_frequent”) and predict_proba returns the class prior.**  Ou seja, ele analisa a proporção, se tem $51\\%$ de zeros, ele vai chutar $51\\%$ zeros e vai acertar na maioria das vezes...\n",
        "\n",
        ">  Então o objetivo do nosso modelo é informar um resultado que não seja por mera chance. "
      ],
      "id": "C2plcTcSf_nR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCWuxS1OjmgU"
      },
      "source": [
        "### Metrificando os modelos com [``Accuracy Score``](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy%20score#sklearn.metrics.accuracy_score)\n",
        "\n",
        "O método ``accuracy_score()`` é um jeito mais automatizado de calcular acurácia de um modelo:\n",
        "\n",
        "```python\n",
        "sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
        "```\n",
        "\n",
        "Accuracy classification score.\n",
        "\n",
        "In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in `y_true`.\n",
        "\n"
      ],
      "id": "KCWuxS1OjmgU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dA7Rfk_hrI4",
        "outputId": "dd795550-a382-4e6f-e913-c96fa7138cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y, y_previsto)"
      ],
      "id": "7dA7Rfk_hrI4",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9119266055045872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSy7DL6ckJvp"
      },
      "source": [
        ""
      ],
      "id": "NSy7DL6ckJvp",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMlVSFKHkk8q"
      },
      "source": [
        "### Separando os dados de treino e teste\n",
        "\n",
        "Existe uma função dentro do SK Learn que faz a \"quebra\" dos dados em conjuntos de treino e teste:\n",
        "\n",
        "```python\n",
        "sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
        "```\n",
        "\n",
        "> por definição o método separa $25\\%$ dos dados para o conjunto de teste, mas isso pode ser modificado nos hiperparâmetros da função."
      ],
      "id": "lMlVSFKHkk8q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1fpW5yKkQhO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "d1fpW5yKkQhO",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZVVFIPUlffk",
        "outputId": "c94fe58f-27b2-4f40-e34b-dc015b8e94bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x,y)\n",
        "\n",
        "print('Dados de Treino: ',len(x_treino),len(y_treino),\n",
        "      '\\nDados de Teste:',len(x_teste), len(y_teste))"
      ],
      "id": "8ZVVFIPUlffk",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dados de Treino:  408 408 \n",
            "Dados de Teste: 137 137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4529dWclnqx"
      },
      "source": [
        "### Treinando modelo logistico com dados de treino\n",
        "\n",
        "Agora podemos usar os dados de treino para treinar o modelo:"
      ],
      "id": "b4529dWclnqx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYk_TF1LlmWw",
        "outputId": "89a52c7f-cb3b-4446-b0fd-0727a778f73d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "modelo_regressao_logistica.fit(x_treino,y_treino)"
      ],
      "id": "dYk_TF1LlmWw",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zv2gsd4mqZ3"
      },
      "source": [
        "y_predito = modelo_regressao_logistica.predict(x_teste)"
      ],
      "id": "0zv2gsd4mqZ3",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO0AIPd7mzpO",
        "outputId": "db6716d2-52b4-4f9e-8d50-6163d6cf1cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy_score(y_teste, y_predito)"
      ],
      "id": "bO0AIPd7mzpO",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8175182481751825"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxowQBa7ymo"
      },
      "source": [
        "### Semente e o ``Random_state``\n",
        "\n",
        "Um ponto importante é que o método ``train_test_split()`` faz uma seleção aleatória dos dados de treino e teste, portanto a cada execução a metrica de qualidade de um modelo muda, veja:"
      ],
      "id": "kSxowQBa7ymo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fa2HGB0m2E-",
        "outputId": "7262a50e-23c9-4dd0-edae-fb5ef2c47999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epocas = {}\n",
        "for epoca in range(10):\n",
        "  # Instanciando modelos\n",
        "  modelo_dummy = DummyClassifier()\n",
        "  modelo_regressao_logistica = LogisticRegression(solver='newton-cg')\n",
        "\n",
        "  # Separação dos dados\n",
        "  x_treino, x_teste, y_treino, y_teste = train_test_split(x,y)\n",
        "\n",
        "  # Ajuste dos modelos\n",
        "  modelo_dummy.fit(x_treino,y_treino)\n",
        "  modelo_regressao_logistica.fit(x_treino,y_treino)\n",
        "\n",
        "  # Predição dos modelos\n",
        "  y_pred_dummy = modelo_dummy.predict(x_teste.to_numpy())\n",
        "  y_pred_logis = modelo_regressao_logistica.predict(x_teste.to_numpy())\n",
        "\n",
        "  # Métricas de qualidade\n",
        "  acc_dummy = accuracy_score(y_teste, y_pred_dummy)\n",
        "  acc_logis = accuracy_score(y_teste, y_pred_logis)\n",
        "\n",
        "  # Exibindo méétricas\n",
        "  epocas[epoca] = (acc_dummy, acc_logis)\n",
        "\n",
        "\n",
        "for chave, valor in epocas.items():\n",
        "  print(f'Epoca {chave} - '+'\\033[34m'+f'Acurácia Dummy: {valor[0].round(2)*100:.2f}% | Acurácia Logistic: {valor[1].round(2)*100:.2f}% '+'\\033[0;0m')"
      ],
      "id": "6fa2HGB0m2E-",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoca 0 - \u001b[34mAcurácia Dummy: 58.00% | Acurácia Logistic: 91.00% \u001b[0;0m\n",
            "Epoca 1 - \u001b[34mAcurácia Dummy: 54.00% | Acurácia Logistic: 85.00% \u001b[0;0m\n",
            "Epoca 2 - \u001b[34mAcurácia Dummy: 50.00% | Acurácia Logistic: 87.00% \u001b[0;0m\n",
            "Epoca 3 - \u001b[34mAcurácia Dummy: 51.00% | Acurácia Logistic: 91.00% \u001b[0;0m\n",
            "Epoca 4 - \u001b[34mAcurácia Dummy: 55.00% | Acurácia Logistic: 82.00% \u001b[0;0m\n",
            "Epoca 5 - \u001b[34mAcurácia Dummy: 50.00% | Acurácia Logistic: 89.00% \u001b[0;0m\n",
            "Epoca 6 - \u001b[34mAcurácia Dummy: 47.00% | Acurácia Logistic: 88.00% \u001b[0;0m\n",
            "Epoca 7 - \u001b[34mAcurácia Dummy: 45.00% | Acurácia Logistic: 87.00% \u001b[0;0m\n",
            "Epoca 8 - \u001b[34mAcurácia Dummy: 53.00% | Acurácia Logistic: 87.00% \u001b[0;0m\n",
            "Epoca 9 - \u001b[34mAcurácia Dummy: 46.00% | Acurácia Logistic: 84.00% \u001b[0;0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP8MiT_bAudx"
      },
      "source": [
        "#### Comentario sobre variação da precisão \n",
        "\n",
        "> Vamos chamar de **Época** um ciclo de separação dos dados, treino e teste. Note na saíída em azul no terminal que para cada época a acurácia do dummy e do logistic muda. Isso acontece porque a forma em que o ``train_test_split()`` seleciona os dados é aleatória, logo cada execução é selecionado um conjunto de dados diferentes e portanto a precisão do modelo varia...\n",
        "\n",
        "#### Núúmeros aleatóórios\n",
        "\n",
        "Para garantir que o modelo selecione sempre o mesmo conjunto de dados podemos definir uma \"Semente\" ou `seed`, que é basicamente um número que origina toda uma sequência de números aleatórios. Com o `numpy` podemos definir uma semente e então fornecemos ela como hiperparâmetro do `train_test_split(random_state=seed)` \n",
        "\n",
        "> **Detalhe**: Em muitos códigos por ai existem pessoas que escolhem uma semente específica. Por exemplo, escolher o número $0$, o dia do aniversário ou até mesmo o número $42$, em homenagem ao [Guia do Mochileiro das Galáxias](https://www.amazon.com.br/guia-mochileiro-das-gal%C3%A1xias/dp/8599296574). **Entretanto vale ressaltar que esse número não é aleatório, pois a chance dele ser escolhido entre varias pessoas é bem maior do que o qualquer outro número devido a influencia na cultura pop...**\n",
        "\n",
        "**Uma sugestão para escolher um número cujo valor irá servir de semente é literalmente digitar varios números com os dedos sem pensar muito (*hahaha!*)**"
      ],
      "id": "rP8MiT_bAudx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_FaeQxh_2jE",
        "outputId": "d2ebe0f1-54e2-42e1-ecc1-475a5e259157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "seed = np.random.seed(120925)\n",
        "\n",
        "epocas = {}\n",
        "for epoca in range(1,11):\n",
        "  # Instanciando modelos\n",
        "  modelo_dummy = DummyClassifier()\n",
        "  modelo_regressao_logistica = LogisticRegression(solver='newton-cg')\n",
        "\n",
        "  # Separação dos dados\n",
        "  x_treino, x_teste, y_treino, y_teste = train_test_split(x,y, random_state=seed)\n",
        "\n",
        "  # Ajuste dos modelos\n",
        "  modelo_dummy.fit(x_treino,y_treino)\n",
        "  modelo_regressao_logistica.fit(x_treino,y_treino)\n",
        "\n",
        "  # Predição dos modelos\n",
        "  y_pred_dummy = modelo_dummy.predict(x_teste.to_numpy())\n",
        "  y_pred_logis = modelo_regressao_logistica.predict(x_teste.to_numpy())\n",
        "\n",
        "  # Métricas de qualidade\n",
        "  acc_dummy = accuracy_score(y_teste, y_pred_dummy)\n",
        "  acc_logis = accuracy_score(y_teste, y_pred_logis)\n",
        "\n",
        "  # Exibindo méétricas\n",
        "  epocas[epoca] = (acc_dummy, acc_logis)\n",
        "\n",
        "\n",
        "for chave, valor in epocas.items():\n",
        "  print(f'Epoca {chave} - '+'\\033[34m'+f'Acurácia Dummy: {valor[0].round(2)*100:.2f}% | Acurácia Logistic: {valor[1].round(2)*100:.2f}% '+'\\033[0;0m')"
      ],
      "id": "p_FaeQxh_2jE",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoca 1 - \u001b[34mAcurácia Dummy: 55.00% | Acurácia Logistic: 85.00% \u001b[0;0m\n",
            "Epoca 2 - \u001b[34mAcurácia Dummy: 53.00% | Acurácia Logistic: 88.00% \u001b[0;0m\n",
            "Epoca 3 - \u001b[34mAcurácia Dummy: 47.00% | Acurácia Logistic: 87.00% \u001b[0;0m\n",
            "Epoca 4 - \u001b[34mAcurácia Dummy: 49.00% | Acurácia Logistic: 82.00% \u001b[0;0m\n",
            "Epoca 5 - \u001b[34mAcurácia Dummy: 47.00% | Acurácia Logistic: 90.00% \u001b[0;0m\n",
            "Epoca 6 - \u001b[34mAcurácia Dummy: 51.00% | Acurácia Logistic: 84.00% \u001b[0;0m\n",
            "Epoca 7 - \u001b[34mAcurácia Dummy: 50.00% | Acurácia Logistic: 87.00% \u001b[0;0m\n",
            "Epoca 8 - \u001b[34mAcurácia Dummy: 44.00% | Acurácia Logistic: 86.00% \u001b[0;0m\n",
            "Epoca 9 - \u001b[34mAcurácia Dummy: 55.00% | Acurácia Logistic: 88.00% \u001b[0;0m\n",
            "Epoca 10 - \u001b[34mAcurácia Dummy: 49.00% | Acurácia Logistic: 84.00% \u001b[0;0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhqPSimzERCh"
      },
      "source": [
        "Agora toda vez que a célula for executada, o resultado de cada época será o mesmo, mas a seleção que ``train_test_split()`` não é a mesma, mas caso seja necessário  selecionar sempre o mesmo conjunto de dados éé sóó fixar um valor em ``random_state``.\n",
        "\n",
        "#### Importancia de uma seleção representativa para treino e teste\n",
        "\n",
        "Como a seleção feita pelo ``train_test_split()`` é aleatória então pode acontecer alguns problemas ao selecionar um conjunto de dados representativo. Vimos que a proporção dos pacientes que foram ou não pra UTI é de $52\\%$ não precisa de UTI e $48\\%$ precisa.\n",
        "\n",
        "Pode acontecer uma situação em que nos dados de treino $90\\%$ dos pacientes não precisam de UTI, ou seja, este conjunto de dados não é representativo do conjunto total de dados. Como também pode acontecer em uma seleção que $90\\%$ dos pacientes precisem de UTI, logo o modelo vai ser ajustado em um conjunto de dados não representativo. **Isso pode ser bom em alguns casos mas pode não ser.**\n",
        "\n",
        "A importancia de que os dados de treino e teste sejam representativos é garantir que o modelo consiga treinar corretamente e também abstrair informações para isso podemos passar o hiperparâmetro ``stratify=y``. Assim o modelo irá garantir que todas as amostras estratificadas sejam representativas em relação aos dados de saída real.\n",
        "\n",
        "Entretanto em outros casos pode ser interessante tentar prever corretamente resultados de amostras estratificadas não representativas. Em outras palavras, ter uma boa taxa de acerto até em dados de teste não representativos. Por exemplo:\n",
        "\n",
        "> A evolução do COVID acontece num janela em média de 15 dias. Portanto, 15 dias após o carnaval é possíível que os dias tenham um aumento expressivo no número de casos e internações, ou seja, num periodo de tempo a quantidade de dados não será representativa em relação aos dados que foram utilizados para treinar o modelo, pois a taxa de contaminação mudou então a quantidade de pessoas que dão entrada no hospital também muda.\n",
        "\n",
        "É importante falar disso pois se treinarmos exclusivamente em dados representativos, ao entrar em uma situação de teste cuja a realidade não é mais representativa do conjunto de treino o modelo pode acabar errando muito mais, e neste caso, erar significa **classificar um paciente para a UTI sem necessidade ou não mandar um paciente, mesmo ele precisando.** \n",
        "\n",
        "> Este tipo de análise condicional, por exemplo \"*Quantos pacientes foram encaminhados à UTI, dado que eles não precisavam*\" ou \"*Quantos pacientes não foram enviados para a UTI dado que eles precisavam da assistencia*\", é referente a diferença fundamental entre **Precisão e Revocação**\n",
        "\n",
        "Uma imagem que ilustra bem a diferença entre precisão e revocação é\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Precis%C3%A3o_e_revoca%C3%A7%C3%A3o.png/262px-Precis%C3%A3o_e_revoca%C3%A7%C3%A3o.png' >\n",
        "\n",
        "> No ambiente hospitalar é de suma importância não só ter uma precisão alta, mas uma também uma revocação. Pois, classificar um paciente que precisa de UTI como uma pessoa que não precisa do serviço pode custar a vida do paciente.\n",
        "\n",
        "\n",
        "Por exemplo, Vamos ver o modelo:"
      ],
      "id": "nhqPSimzERCh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPa1EDgdEaCz",
        "outputId": "a2d4b47a-2a8b-41a7-fca9-a15b7c58d3cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "display(pd.Series(y_pred_logis).value_counts())\n",
        "display(pd.Series(y_teste).value_counts())\n"
      ],
      "id": "OPa1EDgdEaCz",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    80\n",
              "1    57\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    70\n",
              "1    67\n",
              "Name: ICU, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmqsXTwyOg1u"
      },
      "source": [
        "> Note para os valores ``y_pred_logis`` temos a estimativa de 61 pacientes que precisaram da UTI, entretanto na realidade ``y_teste`` temos que 64 realmente precisaram. Isso significa que nosso modelo classificou 3 pacientes que precisavam como pessoas que não precisavam do serviço, dizemos que estes pacientes receberam um *falso negativo*. \n",
        "\n",
        "> **Precisão:** Indica, das classificações corretas, quantas o modelo acertou.\n",
        "\n",
        "> **Revocação**: Indica, das amostras corretas existentes, quantas o modelo conseguiu classificar corretamente."
      ],
      "id": "BmqsXTwyOg1u"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkrjiOrBQkF6"
      },
      "source": [
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x,y, random_state=seed, stratify=y)"
      ],
      "id": "JkrjiOrBQkF6",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDwEtCsd5rhH"
      },
      "source": [
        ""
      ],
      "id": "JDwEtCsd5rhH",
      "execution_count": 28,
      "outputs": []
    }
  ]
}